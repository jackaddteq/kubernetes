##### App lifecycle management

# create deployment
kubectl create deployment webapp1 --image=nginx:1.16-alpine-perl --dry-run -o yaml > webapp1.yml

# create pod
kubectl run nginx --image=nginx --restart=Never --dry-run -o yaml

#rollout
k apply -f webapp2.yml  #nginx:1.17-alpine-perl

kubectl rollout status deployment webapp1
deployment "webapp1" successfully rolled out

kubectl get deployment -o wide | grep webapp1
webapp1   8/10    5            8           27h    nginx        nginx:1.17-alpine                   app=webapp

kubectl rollout undo deploy webapp1
deployment.apps/webapp1 rolled back

kubectl get deployment -o wide | grep webapp1
webapp1   10/10   10           10          27h    nginx        nginx:1.16-alpine                   app=webapp

kp -w

kubectl scale --replicas=5 deployment/webapp1

# CronJobs / ConfigMap

#### Installation, configuration, Validation (kubeadm)
# kubeadmin init, kubeadm join, kubeadm reset


kubectl get componentstatus
NAME                 STATUS    MESSAGE             ERROR
controller-manager   Healthy   ok                  
etcd-0               Healthy   {"health":"true"}   
scheduler            Healthy   ok  


kubectl cluster-info
Kubernetes master is running at https://1a733cd8-97a3-452d-b3e9-8968c5836625.k8s.ondigitalocean.com
CoreDNS is running at https://1a733cd8-97a3-452d-b3e9-8968c5836625.k8s.ondigitalocean.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.


kubectl get nodes
NAME                   STATUS   ROLES    AGE     VERSION
pool-nyqch4qlz-3p9k6   Ready    <none>   5d11h   v1.18.8
pool-nyqch4qlz-3pjhg   Ready    <none>   12d     v1.18.8

#### Networking
$ kubectl expose deployment webapp1 --port=80
service/webapp1 exposed

$ kubectl get svc | grep webapp1
webapp1      ClusterIP   10.245.61.106    <none>        80/TCP    25s

$ kubectl get svc -o=wide | grep webapp1
webapp1      ClusterIP   10.245.61.106    <none>        80/TCP    80s    app=webapp

$ kubectl expose deployment webapp1 --port=80 --dry-run -o yaml
W1027 22:26:38.363187   23564 helpers.go:535] --dry-run is deprecated and can be replaced with --dry-run=client.
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: null
  labels:
    app: webapp1
  name: webapp1
spec:
  ports:
  - port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: webapp
status:
  loadBalancer: {}


#### scheduling
kubectl label nodes node1 disktype=ssd

kubectl get nodes --show-labels=true

# in deployment, select the above node
nodeSelector:
  distype: "ssd"
  
# multiple scheduler
# manually schedule pod without a scheduler

kubectl get events -w # watch event as it happens

#### Security


#### Cluster Maintenence
# Upgrade
backup
upgrade kubeadm
drain the control plane node
kubeadm upgrade plan
kubeadm upgrade apply v1.18.x
kubectl uncordon
upgrade kubectl
systemctl restart kubelet
upgrade worker nodes

## backup/restor
# backup both master node with kubernetes config / etc db
# backup etcd 2 ways: etcd built-in snapshot / volume snapshot

#### Monitor and Logging
## Monitor cluster
# Node problem detector
# Metrics-server
kubectl top nodes
kubectl top pods

## monitor app
Liveness probe  
Readiness probe

## Cluster component log
# node /var/log or /var/log/containers
kube-apiserver.log kube-scheduler.log, kube-controller-manager.log
kubelet.log kube-proxy.log

## app logs
kubectl logs pod1
kubectl describe pod1



### Storage


### Json Path
kubectl get pods -o=jsonpath='{ .items[1].spec.containers[0].image }'  
nginx

kubectl get nodes -o=jsonpath='{.items[*].metadata.name}'    
master node1 node2

kubectl get nodes -o=jsonpath='{.items[*].status.nodeInfo.architecture}' 
amd64 amd64 amd64 

kubectl get nodes -o=jsonpath='{.items[*].status.capacity.cpu}'
12 12 12

kubectl get nodes -o=jsonpath='{.items[*].metadata.name} {.items[*].status.capacity.cpu}'
master node1 node2 12 12 12


kubectl get nodes -o=jsonpath='{.items[*].metadata.name} {"\n"} {.items[*].status.capacity.cpu}'  
master node1 node2 
12 12 12

kubectl get nodes -o=jsonpath='{range .items[*]} {.metadata.name} {"\t"} {.status.capacity.cpu}{"\n"}{end}'
master 12
node1  12
node2  12


kubectl get nodes -o=custom-columns='NODE:.metadata.name, CPU:.status.capacity.cpu'
Node   CPU
master 12
node1  12
node2  12


kubectl get nodes --sort-by=.metadata.name

kubectl get nodes --sort-by=.status.capacity.cpu








